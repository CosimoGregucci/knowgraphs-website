---
date: 2022-02-04
title: 'Research Colloquium presentations by Pere-Lluis Huguet Cabot and Carlos Abelardo Martinez Lorenzo'
---

# Presentation of the paper REBEL: Relation Extraction By End-to-end Language generation
## Pere-Lluis Huguet Cabot - ESR 04, Babelscape

Extracting relation triplets from raw text is a crucial task in **Information Extraction**, enabling multiple applications such as populating or validating knowledge bases, factchecking, and other downstream tasks. However, it usually involves multiple-step pipelines that propagate errors or are limited to a small number of relation types. 

To overcome these issues, we propose the use of autoregressive seq2seq models. Such models have previously been shown to perform well not only in language generation, but also in NLU tasks such as Entity Linking, thanks to their framing as seq2seq tasks. 

In this work, we show how **Relation Extraction** can be simplified by expressing triplets as a sequence of text and we present **REBEL**, a seq2seq model based on BART that performs end-to-end relation extraction for more than 200 different relation types. We show our model's flexibility by fine-tuning it on an array of Relation Extraction and Relation Classification benchmarks, with it attaining state-of-the-art performance in most of them.

The slides of the presentation can be found [here](/downloads/2022-02-04_Huguet_colloquium_slides.pdf).

# Presentation of the paper BabelNet Meaning Representation: A Fully Semantic Formalism to Overcome Language Barriers 
## Carlos Abelardo Martinez Lorenzo - ESR 06, Babelscape

Conceptual representations of meaning have long been the general focus of **Artificial Intelligence** (AI) towards the fundamental goal of machine understanding, with innumerable efforts made in Knowledge Representation, Speech and Natural Language Processing, Computer Vision, inter alia. Even today, at the core of Natural Language Understanding lies the task of **Semantic Parsing**, the objective of which is to convert natural sentences into machine-readable representations.

Through this paper, we aim to revamp the historical dream of AI, by putting forward a novel, all-embracing, **fully semantic meaning representation**, that goes beyond the many existing formalisms. Indeed, we tackle their key limits by fully abstracting text into meaning and introducing language-independent concepts and semantic relations, in order to obtain an interlingual representation. Our proposal aims to overcome the language barrier, and connect not only texts across languages, but also images, videos, speech and sound, and logical formulas, across many fields of AI.

The slides of the presentation can be found [here](/downloads/2022-02-04_Martinez_colloquium_slides.pdf).
